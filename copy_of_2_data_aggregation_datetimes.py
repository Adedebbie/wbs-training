# -*- coding: utf-8 -*-
"""Copy of 2-data-aggregation-datetimes.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ERyzQ7L9DBASchSzP750meV7pSvvlNV-

# Data wrangling and datetimes

Dates and times are a special kind of data type. In this notebook, we will keep exploring the `orders` and `orderlines` datasets from Eniac and learn to deal with them.
"""

import pandas as pd

url = 'https://drive.google.com/file/d/14Y7g5ITyf6LMyPoKc9wr010V9StaCUux/view?usp=sharing' # orderlines.csv
path = 'https://drive.google.com/uc?export=download&id='+url.split('/')[-2]
df = pd.read_csv(path)

df.head()

"""## Data exploration"""

df.info()

"""Two variables need to be modified: 

* `unit_price`: it is detected as an object but it has to be a float. Why is that happening? 
* `date`: needs to be transformed to a date-time format. 

For the moment we will only focus on the `date`. Since it contains both the date and the time, we will transform the data type using the pandas method `.to_datetime()`: 
"""

df['date'] = pd.to_datetime(df['date'])
df.info()

df.describe()

"""You can count the quantity of observations with `.value_counts()`."""

df['sku'].value_counts()

"""**Exercise**: check whether the dates from the `orderlines` dataset match with the dates on the `orders` dataset."""

import pandas as  pd 
url = 'https://drive.google.com/file/d/14Y7g5ITyf6LMyPoKc9wr010V9StaCUux/view?usp=sharing' # orderlines.csv
path = 'https://drive.google.com/uc?export=download&id='+url.split('/')[-2]

print(path)
order_lines = pd.read_csv(path)

url = 'https://drive.google.com/file/d/1BLEHcP-9fm9Rv7A01H3co2XBMnSr66YC/view?usp=sharing' # orders.csv
path = 'https://drive.google.com/uc?export=download&id='+url.split('/')[-2]
orders = pd.read_csv(path)

order_lines.columns

# code here

# don't worry if you cannot solve this exercise completely on your own
# your instructor will solve it with you
# but give it a try :)

"""## Aggregating with pandas

* Grouping and aggregating is one of the main ways to explore data. The main tools to do that with pandas are:
    * [`pandas.DataFrame.groupby()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.groupby.html).
    * [`pandas.DataFrame.agg()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.agg.html?highlight=agg#pandas.DataFrame.agg) 
        * [`pandas.DataFrame.count()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.count.html)
"""

df.head()

"""How many products do we have on each sku?"""

df.groupby('sku').agg({'product_quantity':'count'})

"""Different levels of aggregation answer different business questions:

- **count**: How many times has each product (identified by its `sku`) been purchased in an order? 

- **sum**: How many units of each product have been sold overall? 

- **mean**: How many units/order are sold for each product?
"""

df.groupby('sku').agg({'product_quantity':['count', 'sum', 'mean']})

"""`groupby` can also be combined with other pandas functions to analyse in more depth the datasets."""

df.groupby('sku')[['sku','product_quantity']].describe()

"""Now let's see how can we combine `.groupby()` and `.aggragate()` with `.sort_values()`.

I would like to see the top 10 most sold products on our data (total product quantity). 
"""

(
df
    .groupby('sku')['product_quantity']
    .sum()
    .sort_values(ascending=False).head(10)
)

"""How can we sort values with multiple aggregated functions?"""

(
df
    .groupby('sku')
    .agg({'product_quantity':['sum','count','std','mean','median']})
    .sort_values(('product_quantity','mean'), ascending=False)
)

"""## Working with date time

We will start by creating a weekday column. You will have to combine two functions, [`pandas.DataFrame.assign()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.assign.html) from `pandas` and [`datetime.strftime()`](https://docs.python.org/3/library/datetime.html#strftime-and-strptime-behavior) from `datetime`.

First, let's talk about `.assign()`. It is a useful method for creating new columns:
"""

df.assign(new_colum = 'hi! I am a new column!').head()

"""A new column often is the result of an operation between other columns in the dataframe:"""

df.assign(total_price = df['product_quantity'] * df['unit_price']).head()

"""In Pandas, we can extract strings containing elements like the day of the month, the day of the week, the hour of the day... from `datetime` objects. We do so by using `dt.strftime()` in combination with `strftime` syntax. Find the cheat sheet for this syntax [here](https://strftime.org/). 

You'll understand it better with an example. Let's create the weekday column:
"""

df.assign(week_day = df['date'].dt.strftime('%A')).head()

df['date'].dt.strftime('%B')

"""Now we can sort weekdays by amount of sales:"""

(
df
    .assign(week_day = df['date'].dt.strftime('%A'))
    .groupby('week_day')
    .agg({'product_quantity':['sum','count']})
    .sort_values(('product_quantity','sum'), ascending=False)
)

"""Let's find out the top 1 product (in product quantity) by sku for each weekday:"""

(
df
    .assign(week_day = df['date'].dt.strftime('%A'))
    .groupby(['week_day','sku'])
    .agg({'product_quantity':'sum'})
    .sort_values('product_quantity', ascending=False)
    .reset_index()
    .groupby('week_day')
    .head(1)
)

df.date

"""When using `pd.to_datetime` to convert "objects" like "28-07-1990 03:30:15" to a proper data type, you have captured both the date and the time. Sometimes, you might only need the date (without the time). An easy way to do this is with `dt.date`:"""

df['date'].dt.date.head(3)

"""Note that these are not actually strings, even thoguht the `dtype` that pandas displays for the whole column is `object`:"""

df.date.dt.date[0]

type(df.date.dt.date[0])

"""You can create these `datetime.date` objects from strings using the module `datetime`. This module has a handful of useful functions for dates and times, [check its documentation here](https://docs.python.org/3/library/datetime.html#date-objects)."""

import datetime

datetime.date.fromisoformat("1990-07-28")

"""What we've outlined here is going to become useful and relevant whenever filtering a DataFrame by date, as you will see in the following challenges:

# CHALLENGES

**1. Which are the top 6 orders with the highest number of products sold?**
"""

# code here(
df
    .groupby('sku')['product_quantity']
    .sum()
    .sort_values(ascending=False).head(10)
)

"""**2. Which are the top 6 orders for the 1 of July of 2017?**

Combining `.assign()` with `.dt.date` will help you extract the date of a datetime column and use this information to filter it. Use the `datetime` module and its `date.fromisoformat()` method as we showed above.

Here is an example how to filter the first of January 2017.
"""

# Example
df_date = df.assign(date = df['date'].dt.date).copy()
df_date[df_date['date'] == datetime.date.fromisoformat('2017-01-01')]

# code here

"""**3. Which is the month with the highest number of units sold?** 

Remember to look at the documentation of [`datetime.strftime()`](https://docs.python.org/3/library/datetime.html#strftime-and-strptime-behavior) 
"""

# code here

"""In the results there is an enormous differences between some months. Why do you think this is happening? Do we only have one year of data? In case you have multiple years, filter for only years that are complete to find out the best month for that year.

Tip: the output of the function `.dt.strftime()` is a string, so if you use it in a condition it will only match with strings!
"""

# code here

"""**4. For each month, find the day of the week with the highest amount of products sold** 

See below an example of the expected output.
"""

# code here